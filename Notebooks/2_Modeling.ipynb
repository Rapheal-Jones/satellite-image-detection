{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.io import imread\n",
    "from skimage.util.montage import montage2d\n",
    "from osgeo import gdal\n",
    "\n",
    "import keras_metrics\n",
    "from keras import models\n",
    "from keras import backend as K\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "from keras.layers import Input, GaussianNoise, Conv2D, Activation, concatenate, BatchNormalization, SpatialDropout2D, Cropping2D, ZeroPadding2D\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from functions5 import batch_img_gen, dice_p_bce, dice_coef, jaccard\n",
    "\n",
    "HOME = os.path.expanduser(\"~\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.backend()\n",
    "#K.tensorflow_backend._get_available_gpus()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = HOME + '/new_project/data/pickles/mask_train.pkl'\n",
    "with open(filepath, 'rb') as pkl:\n",
    "    mask_train = pickle.load(pkl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = HOME + '/new_project/data/pickles/tif_train.pkl'\n",
    "with open(filepath, 'rb') as pkl:\n",
    "    tif_train = pickle.load(pkl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_gen = batch_img_gen(4, tif_train, mask_train)          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_x, t_y = next(valid_gen)\n",
    "print('x', t_x.shape, t_x.dtype, t_x.min(), t_x.max())\n",
    "print('y', t_y.shape, t_y.dtype, t_y.min(), t_y.max())\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize = (20, 10))\n",
    "montage_rgb = lambda x: np.stack([montage2d(x[:, :, :, i]) for i in range(x.shape[3])], -1)\n",
    "ax1.imshow(montage_rgb(t_x))\n",
    "ax2.imshow(montage2d(t_y[:, :, :, 0]), cmap = 'Greys')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CROP = 16\n",
    "DROPOUT = 0.25\n",
    "NOISE = 0.1\n",
    "BATCH_SIZE = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_layer = Input((650, 650, 3), name = 'RGB_Input')\n",
    "\n",
    "layer1 = GaussianNoise(NOISE)(in_layer)\n",
    "layer2 = BatchNormalization()(layer1)\n",
    "\n",
    "layer3 = Conv2D(8, [10,10], activation = 'linear', padding = 'same', dilation_rate=(1,1), use_bias=False)(layer2)\n",
    "layer4 = BatchNormalization()(layer3)\n",
    "layer5 = Activation('elu')(layer4)\n",
    "\n",
    "layer6 = Conv2D(8, [10,10], activation = 'linear', padding = 'same', dilation_rate=(1,1), use_bias=False)(layer5)\n",
    "layer7 = BatchNormalization()(layer6)\n",
    "layer8 = Activation('elu')(layer7)\n",
    "\n",
    "layer9 = Conv2D(16, [10,10], activation = 'linear', padding = 'same', dilation_rate=(1,1), use_bias=False)(layer8)\n",
    "layer10 = BatchNormalization()(layer9)\n",
    "layer11 = Activation('elu')(layer10)\n",
    "\n",
    "layer12 = Conv2D(16, [10,10], activation = 'linear', padding = 'same', dilation_rate=(1,1), use_bias=False)(layer11)\n",
    "layer13 = Conv2D(16, [10,10], activation = 'linear', padding = 'same', dilation_rate=(2,2), use_bias=False)(layer11)\n",
    "layer14 = Conv2D(16, [10,10], activation = 'linear', padding = 'same', dilation_rate=(4,4), use_bias=False)(layer11)\n",
    "layer15 = Conv2D(16, [10,10], activation = 'linear', padding = 'same', dilation_rate=(8,8), use_bias=False)(layer11)\n",
    "layer16 = Conv2D(16, [10,10], activation = 'linear', padding = 'same', dilation_rate=(16,16), use_bias=False)(layer11)\n",
    "layer17 = Conv2D(16, [10,10], activation = 'linear', padding = 'same', dilation_rate=(32,32), use_bias=False)(layer11)\n",
    "layer18 = Conv2D(16, [10,10], activation = 'linear', padding = 'same', dilation_rate=(64,64), use_bias=False)(layer11)\n",
    "\n",
    "layer19 = concatenate([layer2, layer12, layer13, layer14, layer15, layer16, layer17, layer18])\n",
    "\n",
    "layer20 = SpatialDropout2D(DROPOUT)(layer19)\n",
    "layer21 = BatchNormalization()(layer20)\n",
    "layer22 = Activation('elu')(layer21)\n",
    "\n",
    "layer23 = Conv2D(32, [10,10], activation = 'linear', padding = 'same', dilation_rate=(1,1), use_bias=False)(layer22)\n",
    "layer24 = BatchNormalization()(layer23)\n",
    "layer25 = Activation('elu')(layer24)\n",
    "\n",
    "layer26 = Conv2D(1, (1, 1), activation='sigmoid', padding='same')(layer25)\n",
    "layer27 = Cropping2D((CROP, CROP))(layer26)\n",
    "layer28 = ZeroPadding2D((CROP, CROP))(layer27)\n",
    "model = models.Model(inputs = [in_layer],\n",
    "                outputs = [layer28])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=RMSprop(lr=1e-6, rho=0.9, epsilon=None, decay=0.0), loss=dice_p_bce, metrics=[dice_coef, 'binary_accuracy', keras_metrics.precision(), keras_metrics.recall()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_path= HOME + \"/new_project/Models/{}_weights.best.hdf5\".format('seg_model')\n",
    "\n",
    "checkpoint = ModelCheckpoint(weight_path, monitor='val_dice_coef', verbose=1, \n",
    "                             save_best_only=True, mode='max', save_weights_only = True)\n",
    "\n",
    "reduceLR = ReduceLROnPlateau(monitor='val_dice_coef', factor=0.5, \n",
    "                                   patience=3, \n",
    "                                   verbose=1, mode='max', epsilon=0.0001, cooldown=2, min_lr=1e-6)\n",
    "\n",
    "early = EarlyStopping(monitor=\"val_dice_coef\", \n",
    "                      mode=\"max\", \n",
    "                      patience=15)\n",
    "\n",
    "callbacks_list = [checkpoint, early, reduceLR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_items = len(tif_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_gen = batch_img_gen(BATCH_SIZE)\n",
    "loss_history = [model.fit_generator(batch_img_gen(BATCH_SIZE), \n",
    "                             steps_per_epoch=min(total_items//BATCH_SIZE, 100),\n",
    "                             epochs=120, \n",
    "                             validation_data = valid_gen,\n",
    "                             validation_steps = min(total_items//BATCH_SIZE, 50),\n",
    "                             callbacks=callbacks_list,\n",
    "                             workers=1, use_multiprocessing=True)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seg_model.load_weights(weight_path)\n",
    "# seg_model.save('model12_full.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
